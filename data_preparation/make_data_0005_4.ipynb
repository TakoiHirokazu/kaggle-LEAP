{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc0e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climsim_utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103c2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = \"04\"\n",
    "save_month = \"4\"\n",
    "year = \"0005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a10ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_inputs = ['state_t',\n",
    "             'state_q0001',\n",
    "             'state_q0002',\n",
    "             'state_q0003',\n",
    "             'state_u',\n",
    "             'state_v',\n",
    "             'state_ps',\n",
    "             'pbuf_SOLIN',\n",
    "             'pbuf_LHFLX',\n",
    "             'pbuf_SHFLX',\n",
    "             'pbuf_TAUX',\n",
    "             'pbuf_TAUY',\n",
    "             'pbuf_COSZRS',\n",
    "             'cam_in_ALDIF',\n",
    "             'cam_in_ALDIR',\n",
    "             'cam_in_ASDIF',\n",
    "             'cam_in_ASDIR',\n",
    "             'cam_in_LWUP',\n",
    "             'cam_in_ICEFRAC',\n",
    "             'cam_in_LANDFRAC',\n",
    "             'cam_in_OCNFRAC',\n",
    "             'cam_in_SNOWHICE',\n",
    "             'cam_in_SNOWHLAND',\n",
    "             'pbuf_ozone', # outside of the upper troposphere lower stratosphere (UTLS, corresponding to indices 5-21), variance in minimal for these last 3 \n",
    "             'pbuf_CH4',\n",
    "             'pbuf_N2O']\n",
    "\n",
    "v2_outputs = ['ptend_t',\n",
    "              'ptend_q0001',\n",
    "              'ptend_q0002',\n",
    "              'ptend_q0003',\n",
    "              'ptend_u',\n",
    "              'ptend_v',\n",
    "              'cam_out_NETSW',\n",
    "              'cam_out_FLWDS',\n",
    "              'cam_out_PRECSC',\n",
    "              'cam_out_PRECC',\n",
    "              'cam_out_SOLS',\n",
    "              'cam_out_SOLL',\n",
    "              'cam_out_SOLSD',\n",
    "              'cam_out_SOLLD']\n",
    "\n",
    "vertically_resolved = ['state_t', \n",
    "                       'state_q0001', \n",
    "                       'state_q0002', \n",
    "                       'state_q0003', \n",
    "                       'state_u', \n",
    "                       'state_v', \n",
    "                       'pbuf_ozone', \n",
    "                       'pbuf_CH4', \n",
    "                       'pbuf_N2O', \n",
    "                       'ptend_t', \n",
    "                       'ptend_q0001', \n",
    "                       'ptend_q0002', \n",
    "                       'ptend_q0003', \n",
    "                       'ptend_u', \n",
    "                       'ptend_v']\n",
    "\n",
    "ablated_vars = ['ptend_q0001',\n",
    "                'ptend_q0002',\n",
    "                'ptend_q0003',\n",
    "                'ptend_u',\n",
    "                'ptend_v']\n",
    "\n",
    "v2_vars = v2_inputs + v2_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d29a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col_names = []\n",
    "ablated_col_names = []\n",
    "for var in v2_vars:\n",
    "    if var in vertically_resolved:\n",
    "        for i in range(60):\n",
    "            train_col_names.append(var + '_' + str(i))\n",
    "            if i < 12 and var in ablated_vars:\n",
    "                ablated_col_names.append(var + '_' + str(i))\n",
    "    else:\n",
    "        train_col_names.append(var)\n",
    "\n",
    "input_col_names = []\n",
    "for var in v2_inputs:\n",
    "    if var in vertically_resolved:\n",
    "        for i in range(60):\n",
    "            input_col_names.append(var + '_' + str(i))\n",
    "    else:\n",
    "        input_col_names.append(var)\n",
    "\n",
    "output_col_names = []\n",
    "for var in v2_outputs:\n",
    "    if var in vertically_resolved:\n",
    "        for i in range(60):\n",
    "            output_col_names.append(var + '_' + str(i))\n",
    "    else:\n",
    "        output_col_names.append(var)\n",
    "\n",
    "assert(len(train_col_names) == 17 + 60*9 + 60*6 + 8)\n",
    "assert(len(input_col_names) == 17 + 60*9)\n",
    "assert(len(output_col_names) == 60*6 + 8)\n",
    "assert(len(set(output_col_names).intersection(set(ablated_col_names))) == len(ablated_col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8359812",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = './grid_info/ClimSim_low-res_grid-info.nc'\n",
    "norm_path = './preprocessing/normalizations/'\n",
    "\n",
    "grid_info = xr.open_dataset(grid_path)\n",
    "input_mean = xr.open_dataset(norm_path + 'inputs/input_mean.nc')\n",
    "input_max = xr.open_dataset(norm_path + 'inputs/input_max.nc')\n",
    "input_min = xr.open_dataset(norm_path + 'inputs/input_min.nc')\n",
    "output_scale = xr.open_dataset(norm_path + 'outputs/output_scale.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf7d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_utils(grid_info = grid_info, \n",
    "                  input_mean = input_mean, \n",
    "                  input_max = input_max, \n",
    "                  input_min = input_min, \n",
    "                  output_scale = output_scale)\n",
    "\n",
    "data.set_to_v2_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35133c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not normalize\n",
    "data.normalize = False\n",
    "\n",
    "# create training data\n",
    "\n",
    "# set data path for training data\n",
    "data.data_path = './storage/leap/all_data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55bf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_regexps(data_split = 'train', \n",
    "                 regexps = [f'E3SM-MMF.mli.{year}-{month}-*-*.nc']) # first month of year 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd732e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set temporal subsampling\n",
    "data.set_stride_sample(data_split = 'train', stride_sample = 1)\n",
    "\n",
    "# create list of files to extract data from\n",
    "data.set_filelist(data_split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe99a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "data_loader = data.load_ncdata_with_generator(data_split = 'train')\n",
    "npy_iterator = list(data_loader.as_numpy_iterator())\n",
    "npy_input = np.concatenate([npy_iterator[x][0] for x in range(len(npy_iterator))])\n",
    "npy_output = np.concatenate([npy_iterator[x][1] for x in range(len(npy_iterator))])\n",
    "train_npy = np.concatenate([npy_input, npy_output], axis = 1)\n",
    "train_index = [\"train_\" + str(x) for x in range(train_npy.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc4d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping cam_in_SNOWHICE because of strange values\n",
      "(829440, 924)\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(train_npy, index = train_index, columns = train_col_names)\n",
    "train.index.name = 'sample_id'\n",
    "print('dropping cam_in_SNOWHICE because of strange values')\n",
    "train.drop('cam_in_SNOWHICE', axis=1, inplace=True)\n",
    "\n",
    "# ASSERT, SHAPE, CSV, PRINT\n",
    "assert sum(train.isnull().any()) == 0\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb0a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "train.to_parquet(f\"./storage/leap/data/train_{year}/train_{year}_{save_month}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0110474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505e2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
